# -*- coding: utf-8 -*-
"""MODEL CNN BIASA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D0Wv3ukVO8jV0Z8dVMhL4JywjlBlzj0D
"""

import os
import zipfile


path_to_dataset = "/content/Citra_BISIND(Augmented).zip"


extract_to = os.path.join(os.path.dirname(path_to_dataset), "extracted")


os.makedirs(extract_to, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(path_to_dataset, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print(f"Extracted {path_to_dataset} to {extract_to}")

import os

def count_images_per_folder(root_dir):
  """Counts the number of images in each subfolder of the root directory.

  Args:
    root_dir: The path to the root directory.

  Returns:
    A dictionary where keys are folder names and values are the number of images
    in each folder.
  """

  image_counts = {}
  for folder_name in os.listdir(root_dir):
    folder_path = os.path.join(root_dir, folder_name)
    if os.path.isdir(folder_path):
      image_count = 0
      for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
          image_count += 1
      image_counts[folder_name] = image_count
  return image_counts

# Example usage:
image_counts = count_images_per_folder("/content/CitraBISINDO")
for folder, count in image_counts.items():
  print(f"Folder: {folder}, Image Count: {count}")

"""Pemodelan

"""

import os
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from PIL import Image

# Path to the augmented dataset
dataset_path = "/content/CitraBISINDO"
target_size = (128, 128)  # Resize all images to 128x128
num_classes = len(os.listdir(dataset_path))  # Number of classes (A-Z)

# Load and preprocess the dataset
def load_data(dataset_path, target_size):
    images = []
    labels = []
    class_labels = sorted(os.listdir(dataset_path))
    class_to_index = {class_name: idx for idx, class_name in enumerate(class_labels)}

    for class_name in class_labels:
        class_folder = os.path.join(dataset_path, class_name)
        for file_name in os.listdir(class_folder):
            file_path = os.path.join(class_folder, file_name)
            if file_name.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff')):
                try:
                    image = Image.open(file_path).convert('RGB')
                    image = image.resize(target_size)
                    images.append(np.array(image))
                    labels.append(class_to_index[class_name])
                except Exception as e:
                    print(f"Error loading image {file_path}: {e}")
    return np.array(images), np.array(labels), class_labels

print("Loading data...")
images, labels, class_labels = load_data(dataset_path, target_size)

# Normalize images to [0, 1]
images = images / 255.0

# Stratified train-test split
X_train, X_val, y_train, y_val = train_test_split(
    images, labels, test_size=0.2, stratify=labels, random_state=42
)

# One-hot encode labels
y_train = to_categorical(y_train, num_classes=num_classes)
y_val = to_categorical(y_val, num_classes=num_classes)

# Define the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
print("Training the model...")
history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    validation_data=(X_val, y_val)
)

import matplotlib.pyplot as plt

# Function to plot training history
def plot_history(history, model_name):
    # Plot training & validation accuracy values
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title(f'{model_name} - Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'])

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title(f'{model_name} - Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(['Train', 'Validation'])

    # Show the plots
    plt.tight_layout()
    plt.show()

model_name = "CNN_Sign_Language"
   # Plot training history
plot_history(history, model_name)

# Save the model
model.save("/content/sign_language_model.h5")
print("Model saved as sign_language_model.h5")

# Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Validation Accuracy: {accuracy * 100:.2f}%")

import os
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import files

# Load the trained model
model = load_model('/content/sign_language_model.h5')

# Function to preprocess the uploaded image
def preprocess_image(img_path, target_size=(128, 128)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize
    return img_array

# Upload image from local device
uploaded = files.upload()

for fn in uploaded.keys():
    # Preprocess the image
    img_path = fn
    img_array = preprocess_image(img_path)

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    # Class labels (replace with your actual class labels)
    class_labels = sorted(os.listdir("/content/CitraBISINDO")) # Assuming your dataset directory is still the same

    # Display the image and the prediction
    plt.imshow(image.load_img(img_path))
    plt.title(f"Predicted Class: {class_labels[predicted_class]}")
    plt.axis('off')  # Hide axis ticks
    plt.show()

import os
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import files

# Load the trained model
model = load_model('/content/sign_language_model.h5')

# Function to preprocess the uploaded image
def preprocess_image(img_path, target_size=(128, 128)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize
    return img_array

# Upload image from local device
uploaded = files.upload()

for fn in uploaded.keys():
    # Preprocess the image
    img_path = fn
    img_array = preprocess_image(img_path)

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    # Class labels (replace with your actual class labels)
    class_labels = sorted(os.listdir("/content/CitraBISINDO")) # Assuming your dataset directory is still the same

    # Display the image and the prediction
    plt.imshow(image.load_img(img_path))
    plt.title(f"Predicted Class: {class_labels[predicted_class]}")
    plt.axis('off')  # Hide axis ticks
    plt.show()

import os
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import files

# Load the trained model
model = load_model('/content/sign_language_model.h5')

# Function to preprocess the uploaded image
def preprocess_image(img_path, target_size=(128, 128)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize
    return img_array

# Upload image from local device
uploaded = files.upload()

for fn in uploaded.keys():
    # Preprocess the image
    img_path = fn
    img_array = preprocess_image(img_path)

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    # Class labels (replace with your actual class labels)
    class_labels = sorted(os.listdir("/content/CitraBISINDO")) # Assuming your dataset directory is still the same

    # Display the image and the prediction
    plt.imshow(image.load_img(img_path))
    plt.title(f"Predicted Class: {class_labels[predicted_class]}")
    plt.axis('off')  # Hide axis ticks
    plt.show()

import os
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import files

# Load the trained model
model = load_model('/content/sign_language_model.h5')

# Function to preprocess the uploaded image
def preprocess_image(img_path, target_size=(128, 128)):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize
    return img_array

# Upload image from local device
uploaded = files.upload()

for fn in uploaded.keys():
    # Preprocess the image
    img_path = fn
    img_array = preprocess_image(img_path)

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    # Class labels (replace with your actual class labels)
    class_labels = sorted(os.listdir("/content/CitraBISINDO")) # Assuming your dataset directory is still the same

    # Display the image and the prediction
    plt.imshow(image.load_img(img_path))
    plt.title(f"Predicted Class: {class_labels[predicted_class]}")
    plt.axis('off')  # Hide axis ticks
    plt.show()